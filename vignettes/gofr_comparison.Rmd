---
title: "GOFR Comparison"
output:
  pdf_document:
    number_sections: true
    df_print: kable
    toc: true
  html_notebook:
    number_section: true
    toc: true
---

From `r system("git config --get remote.origin.url", intern = TRUE)`
on `r date()`, generated by `r Sys.info()[["effective_user"]]`.

# Overview

This notebook concentrates on how we calculate the goodness-of-fit ratio (GOFR).
It combines information from the "Accuracy Metrics" vignette and the "map comparison"
vignette. If you want to run this notebook, check out the Github project,
create a subdirectory of the project called `inst/extdata`, and unzip the zipfile
in that directory. It will create subdirectories for the maps, the density maps,
and the necessary shapefiles. You also need to install the popbioko project,
which Rstudio does with a button under the Build menu.

We had a paper with a GOFR table and a GOFR explanation paragraph, and we were
happy. Everything made sense. Then Drew changed everything, and now neither the
explanations nor the numbers make sense. What happened, and how do we return to
our happy place?

For one, the data changed. There are two kinds of maps, population maps and density
maps. The density maps estimate population density from the population maps.
We have estimated density maps in two different ways. One is to average over all pixels
within a radius. The other is to more precisely draw a circle that crosses those same
pixels and average area that covers parts of pixels.

* Population map, which is a count in a square
* Density map that integrates a $1\:\mbox{km}^2$ disc around each cell center.
* Density map that sums pixels around a cell center.

I suspect that the size of the radius for blurring, for the two density maps,
is different. I say this because plots showed more blurring for the integrated
ones, and I did testing on them to see that they have $1\:\mbox{km}^2$ under the disc.

For another, I've been trying modifications to the GOFR because they seemed
easier to explain and they didn't seem like they would make a difference.
I was wrong. Let's take a look.

# Possible GOFRs

## The Actual GOFR

Define $H(x)$ is the gold standard at pixel $x$. Make $\hat{H}(x)$ the observed
map. (We switched which variable gets the hat after Sean said the observed values
generally get the hat for statistics.)
We can use either population maps or density maps here. Use $\langle H\rangle$
for the mean of the gold standard and $\langle \hat{H}\rangle$ for the mean of the
population map.
$$
  GOFR = \frac{\sum_x(\hat{H}(x) - H(x))^2}{\sum_x(\hat{H}(x) - \langle H\rangle)}
$$
## Normalize by Gold Standard Variance
I thought it was easier to say that this is sum of squared errors per pixel divided
by gold standard variance.
$$
  GOFR = \frac{\sum_x(\hat{H}(x) - H(x))^2}{\sum_x(H(x) - \langle H\rangle)}
$$


## Normalize by Observed Variance
Or normalize by the map variance, if that works. The numbers look less huge.
$$
  GOFR = \frac{\sum_x(\hat{H}(x) - H(x))^2}{\sum_x(\hat{H}(x) - \langle \hat{H}\rangle)}
$$
# Look at Numbers

I've put the maps into a zip directory. These come from the "Get Data" vignette
and include both population maps and raster maps. You'll see that they have
a regular naming scheme.

## Load Datasets
Load population maps. They will be in lat-long. This chunk will print the available maps.
The original set are "HRSL on HRSL fine," "LandScan on LandScan coarse," and
"WorldPop on WorldPop fine."
```{r load_maps}
data_dir <- rprojroot::find_rstudio_root_file("inst/extdata")
map_root <- fs::path(data_dir, "aligned")
files <- list.files(map_root, pattern = "*.tif$")
files_df <- popbioko::filenames_to_description(files)
maps <- lapply(files, function(x) raster::raster(fs::path(map_root, x)))
names(maps) <- rownames(files_df)
files_df
```

Load density maps. They will be in UTM projection.
```{r load_densities}
density_dir <- fs::path(data_dir, "density_raster")
density <- lapply(files_df$filename, function(x) raster::raster(fs::path(density_dir, x)))
names(density) <- names(maps)
```

In order to calculate the GOFR on smaller regions, we'll need shapefiles, too.
The incoming shapefile is in UTM, which is approprate for overlay on the
density maps but not the population maps, which are lat-long, so convert it.
```{r load_admin2, results = "hide", message = FALSE}
# The input map is in UTM, so we transform it to lat-long in order to agree
# with the raster coordinates of all rasters.
admin2_projected_sf <- sf::st_read(rprojroot::find_package_root_file(
  "inst/extdata/admin2/bioko_admin2_fulldistricts.shp"))
admin2_projected_st <- as(sf::st_geometry(admin2_projected_sf), "Spatial")
admin2_sf <- sf::st_transform(admin2_projected_sf, raster::crs(maps[1][[1]]))
admin2_st <- as(sf::st_geometry(admin2_sf), "Spatial")
admin2_st_df <- as(admin2_sf[, "OBJECTID"], "Spatial")
tmap::tm_shape(admin2_sf) + tmap::tm_polygons("admin2")
```

## GOFR Runner

These functions run the calculations. We put this here to get it out of the way.
It's all about intersecting maps and organizing the data.
```{r whole_island_gofr}
calculate_gofr <- function(normalize_gofr, gofr_map_type, gofr_algorithm) {
  # For each grid and resolution, there should be a map and a BIMEP version of that map.
  admin_names <- c("Baney", "Malabo", "Luba", "Riaba")
  # If these are out of order, then the names in admin_names are in the wrong order.
  stopifnot(admin2_sf$OBJECTID == 1:4)
  gofr <- unique(files_df[, c("grid", "resolution")])
  rownames(gofr) <- paste(gofr$grid, gofr$resolution)
  gofr$GOFR <- numeric(nrow(gofr))
  gofr$Baney <- numeric(nrow(gofr))
  gofr$Malabo <- numeric(nrow(gofr))
  gofr$Luba <- numeric(nrow(gofr))
  gofr$Riaba <- numeric(nrow(gofr))
  
  for (gofr_make_idx in 1:nrow(gofr)) {
    gofr_grid <- gofr[gofr_make_idx, "grid"]
    gofr_resolution <- gofr[gofr_make_idx, "resolution"]
    gofr_pair_df <- files_df[files_df$grid == gofr_grid & files_df$resolution == gofr_resolution, ]
    pops_bimep <- raster::getValues(gofr_map_type[gofr_pair_df[gofr_pair_df$source == "BIMEP", "name"]][[1]])
    compare_map <- gofr_map_type[gofr_pair_df[gofr_pair_df$source != "BIMEP", "name"]][[1]]
    pops_map <- raster::getValues(compare_map)
    stopifnot(length(pops_bimep) == length(pops_map))
    
    # GOFR for the whole island.
    gofr$GOFR[gofr_make_idx] <- gofr_algorithm(pops_bimep, pops_map, normalize_gofr)
    
    # Iterate through the four admin2 by ID.
    is_lonlat <- raster::isLonLat(raster::crs(gofr_map_type[[1]][[1]]))
    if (is_lonlat) {
      use_map <- admin2_st
    } else {
      use_map <- admin2_projected_st
    }
    segmented <- raster::getValues(raster::rasterize(
      use_map, compare_map, field = admin2_sf$OBJECTID))
    for (adm2_idx in 1:length(admin_names)) {
      sub_bimep <- pops_bimep[segmented == adm2_idx]
      sub_pops <- pops_map[segmented == adm2_idx]
      gofr[[admin_names[adm2_idx]]][gofr_make_idx] <- gofr_algorithm(sub_bimep, sub_pops, normalize_gofr)
    }
  }
  gofr
}

#' This makes a dataframe with both unnormalized and normalized gofr, ready to print.
gofr_table <- function(gofr_map_type, gofr_algorithm, map_choice) {
  gofr_absolute <- calculate_gofr(FALSE, gofr_map_type, gofr_algorithm)
  gofr_normalized <- calculate_gofr(TRUE, gofr_map_type, gofr_algorithm)
  cols <- c("grid", "resolution", "GOFR", "Baney", "Luba", "Malabo", "Riaba")
  gofr_table <- rbind(gofr_absolute[map_choice, cols], gofr_normalized[map_choice, cols])
  gofr_table
}
```

## Run Several GOFR Algorithms

Here, you can run whatever you want.
```{r the_algorithms}
#' This is the one we used before.
gofr_of_maps_original <- function(pops_map, pops_bimep, normalize = FALSE) {
  if (normalize) {
    pops_bimep <- pops_bimep / sum(pops_bimep, na.rm = TRUE)
    pops_map <- pops_map / sum(pops_map, na.rm = TRUE)
  }
  pixel_cnt <- sum(is.finite(pops_map))
  # Ignore NA because they tell us where there is water. Rasters are designed to agree on water location.
  pixel_error <- sum((pops_map - pops_bimep)^2, na.rm = TRUE)
  pixel_error / sum((pops_map - mean(pops_bimep, na.rm = TRUE))^2, na.rm = TRUE)
}

# This divides sum of squared error by variance of the gold standard
gofr_of_maps_gold_variance <- function(pops_map, pops_bimep, normalize = FALSE) {
  if (normalize) {
    pops_bimep <- pops_bimep / sum(pops_bimep, na.rm = TRUE)
    pops_map <- pops_map / sum(pops_map, na.rm = TRUE)
  }
  pixel_cnt <- sum(is.finite(pops_map))
  # Ignore NA because they tell us where there is water. Rasters are designed to agree on water location.
  pixel_error <- sum((pops_map - pops_bimep)^2, na.rm = TRUE) / pixel_cnt
  pixel_error / var(pops_bimep, na.rm = TRUE)
}

# This divides sum of squared error by variance of the map under observation.
gofr_of_maps_observed_variance <- function(pops_map, pops_bimep, normalize = FALSE) {
  if (normalize) {
    pops_bimep <- pops_bimep / sum(pops_bimep, na.rm = TRUE)
    pops_map <- pops_map / sum(pops_map, na.rm = TRUE)
  }
  pixel_cnt <- sum(is.finite(pops_map))
  # Ignore NA because they tell us where there is water. Rasters are designed to agree on water location.
  pixel_error <- sum((pops_map - pops_bimep)^2, na.rm = TRUE) / pixel_cnt
  pixel_error / var(pops_map, na.rm = TRUE)
}

original_resolutions <- c(2, 3, 6)
coarse_resolutions <- c(1, 3, 5)
```

### Maps with Original Resolutions, some fine, some coarse

#### Maps of counts

```{r using_original_resolutions}
# Set to maps or density for original map or density surface.
gofr_table(maps, gofr_of_maps_original, original_resolutions)
```
```{r divide_by_gold_variance}
gofr_table(maps, gofr_of_maps_gold_variance, original_resolutions)
```

```{r divide_by_obs_variance}
gofr_table(maps, gofr_of_maps_observed_variance, original_resolutions)
```

#### Maps of densities
Now do the same for densities.
```{r density_original_gofr}
gofr_table(density, gofr_of_maps_original, original_resolutions)
```

```{r density_divide_by_gold_variance}
gofr_table(density, gofr_of_maps_gold_variance, original_resolutions)
```

```{r density_divide_by_obs_variance}
gofr_table(density, gofr_of_maps_observed_variance, original_resolutions)
```


### Maps with coarse resolutions

#### Maps of counts

```{r again_coarse}
gofr_table(maps, gofr_of_maps_original, coarse_resolutions)
```

```{r divide_by_gold_variance_coarse}
gofr_table(maps, gofr_of_maps_gold_variance, coarse_resolutions)
```

```{r divide_by_obs_variance_coarse}
gofr_table(maps, gofr_of_maps_observed_variance, coarse_resolutions)
```

#### Maps of densities
Now do the same for densities.
```{r density_original_gofr_coarse}
gofr_table(density, gofr_of_maps_original, coarse_resolutions)
```

```{r density_divide_by_gold_variance_coarse}
gofr_table(density, gofr_of_maps_gold_variance, coarse_resolutions)
```

```{r density_divide_by_obs_variance_coarse}
gofr_table(density, gofr_of_maps_observed_variance, coarse_resolutions)
```

# SSD Profiles (From Dave's Notes)

This section is included from the Accuracy Metrics vignette. I don't have the data
here, but the notes might help somebody.

Population distributions describe how many people live in each place. For the following, let $P_i (x)$ denote the value of the i$^{th}$ distribution map at a point in space $x$ defined over a space, $X$, where $X$ is the area grid or the sectors grid. We consider comparisons of maps over the same grid space $X$. To do so, we based comparisons on two aspects. First, we measured accuracy by land area and by population density. The difference between land area and population density is that the former measures the distribution of population density of the units, while the second measures the same population density weighted by population. In other words, the accuracy of land area summaries of human population distributions look at the distribution of the population density over land (\textit{i.e.} How is the population distributed at a typical point in space?) whereas the accuracy of population density summaries of human population distributions look at the distribution of the properties of the people (\textit{i.e.} How is population distributed for a typical person?). We considered the cumulative distribution function (CDF), $F_i$, where $y$ is sorted for some particular map over the range of all the values in $P_i(x)$ for $x \in X$.

%We compare two distributions using the Cramer-von Mises (CvM) test: 
%$$\sum_{y}  \left(F_i\left(y\right)-F_j\left(y\right)\right)^2 w(y) dx. $$ 
%The CvM distribution test is a useful first-order metric for measuring accuracy. In general, we will take $w(y)=1$, but we can also choose $w(y)$ weights to emphasize the accuracy of maps in rural or urban settings. 

Another simple measure of the difference between two maps is %the unweighted CvM, which is the sum of 
the sum of squared differences of distributions (SSD): 
$$\sum_{x\in X} \left(P_i \left(x\right)-P_j\left(x\right)\right)^2$$
One reference point for comparison is against a map that takes the mean value everywhere (i.e. an information-less map, in which each pixel has the same population density, the total population divided by total land area). The overall variance of the population distribution is: 
$$V = \sum_{x\in X} \left(P_i \left(x\right)-\left<P\right>\right)^2 $$
By comparison, we can examine the SSD of any map and the gold standard, $P"$: 
$$D = \sum_{x\in X} \left(P_i \left(x\right)-P"\left(x\right)\right)^2 $$
Maps that are close to the truth will have a lower SSD. A single number summary is the ratio of the SSD to the total variance, $D/V$. We call $D/V$ the “SSD ratio”, noting it is possible for a map to be so bad that $D/V > 1$. To set some standards for interpreting metrics, we compared the SSD ratio of population maps at 1x1 km resolution to population maps aggregated at 5x5 km, as well as at the community and district levels, and for the whole island. various levels  administrative units. By comparing the SSD by granularity, there is a basis for assessing the accuracy of maps developed using different methodologies. We can use the deviance test for a set of nested population surfaces to compare how well some particular high resolution map compares to a coarser version of the map. For example, how much more accurate is a 1x1 km map than a map of population by administrative unit?  For any set of nested maps, we can compare the accuracy gain by granularity by looking at the deviance ratio for successively mapped populations.


With a gold standard, the weighted SSD can be used to develop a tailored measure of accuracy: 
$$D_w = \sum_{x\in X} \left(P_i \left(x\right)-P"\left(x\right)\right)^2 w(P"(x)) $$
These two different metrics can be used diagnostically: when an accurate map is misaligned, it will have the proper CDF, but it could appear to be highly inaccurate by the SSD ratio test. 

```{r get_figures, eval = FALSE}
##### GET RELATIVE POPULATION FIGURES
mcpoptot <- sum(popk$pop1k)
wppoptot <- sum(popk$wppop)
lspoptot <- sum(popk$lspop)
fbpoptot <- sum(popk$popfb)
popk$pop1kp <- popk$pop1k / mcpoptot
popk$wppopp <- popk$wppop / wppoptot
popk$lspopp <- popk$lspop / lspoptot
popk$fbpopp <- popk$popfb / fbpoptot

##### BUILD THE 5KM GRID

km5 <- read.csv(fs::path(params$source_data, "5x5grid.csv"), sep = ",")
x <- c("areaId", "fiveId")
names(km5) <- x

popk <- merge(popk, km5, by = "areaId", all.x = T)

pop5k <- aggregate(list(mcpop = popk$pop1kp, wppop = popk$wppopp, lspop = popk$lspopp, popfb = popk$fbpopp),
  by = list(fiveId = popk$fiveId),
  FUN = mean
)

popk <- merge(popk, list(
  fiveId = pop5k$fiveId, mcpop5 = pop5k$mcpop, wppop5 = pop5k$wppop, lspop5 = pop5k$lspop,
  fbpop5 = pop5k$popfb
), by = "fiveId", all.x = T)

##### BUILD THE ADMIN4 LAYER

ad4 <- read.csv(fs::path(params$source_data, "AreaByComm.csv"), sep = ",")
x <- c("areaId", "admin4", "admin4Id")
names(ad4) <- x
ad4_2 <- read.csv("AreaByNPad4.csv", sep = ",") ### missed points due to National Parks, except for 3 (areaId 94, 1025 and 2136)
x <- c("areaId", "admin4Id")
names(ad4_2) <- x
ad4_2$admin4 <- "NP-corrected"
ad4_2$admin4Id <- ifelse(ad4_2$admin4Id == "", "NN", as.character(ad4_2$admin4Id))

ad4_3 <- rbind(ad4, ad4_2)
ad4_3$dup <- duplicated(ad4_3$areaId)
ad4_3 <- ad4_3[-which(ad4_3$dup == T), ]

popk <- merge(popk, ad4_3[, 1:3], by = "areaId", all.x = T)

popad4 <- aggregate(list(mcpop = popk$pop1kp, wppop = popk$wppopp, lspop = popk$lspopp, popfb = popk$fbpopp),
  by = list(admin4Id = popk$admin4Id),
  FUN = mean
)

popk <- merge(popk, list(
  admin4Id = popad4$admin4Id, mcpopad4 = popad4$mcpop, wppopad4 = popad4$wppop, lspopad4 = popad4$lspop,
  fbpopad4 = popad4$popfb
), by = "admin4Id", all.x = T)

##### BUILD THE ADMIN2 LAYER

ad2 <- read.csv(fs::path(params$source_data, "AreaByDistrict.csv"), sep = ",")
x <- c("areaId", "admin2", "admin2Id", "admin2type")
names(ad2) <- x

popk <- merge(popk, ad2, by = "areaId", all.x = T)

popad2 <- aggregate(list(mcpop = popk$pop1kp, wppop = popk$wppopp, lspop = popk$lspopp, popfb = popk$fbpopp),
  by = list(admin2 = popk$admin2),
  FUN = mean
)

popk <- merge(popk, list(
  admin2 = popad2$admin2,
  mcpopad2 = popad2$mcpop,
  wppopad2 = popad2$wppop,
  lspopad2 = popad2$lspop,
  fbpopad2 = popad2$popfb
), by = "admin2", all.x = T)
```


```{r define_ratios, eval = FALSE}
ssdRatioF <- function(map, gold, norm = TRUE) {
  # 0 is perfect
  # <1 implies the map is an improvement
  # >1 is awful
  # Inf assigns values to empty places
  # -1
  if (sum(gold) > 0) {
    if (norm == TRUE) {
      gold <- gold / sum(gold)
      map <- map / sum(map)
    }
    R <- sum((map - gold)^2) / sum((gold - mean(gold))^2)
  } else {
    if (sum(map) == 0) {
      R <- 0
    } else {
      R <- -log10(sum(map)) # Inf
    }
  }
  return(R)
}

ssdRatio <- function(map, gold, P = NULL, norm = TRUE) {
  if (is.null(P)) {
    RR <- ssdRatioF(map, gold, norm)
  } else {
    ids <- unique(P)
    L <- length(ids)
    RR <- rep(-1, L)
    for (i in 1:L) {
      ix <- which(ids[i] == P)
      if (length(ix) > 0) RR[i] <- ssdRatioF(map[ix], gold[ix], norm)
    }
    RR <- data.frame(RR, names = ids)
  }
  return(RR)
}

ssdRatioT <- function(map, gold, P = NULL) {
  gold <- gold / sum(gold)
  map <- map / sum(map)
  if (is.null(P)) {
    goldMeans <- mean(gold)
  } else {
    goldMeans <- 0 * gold
    ids <- unique(P)
    L <- length(ids)
    for (i in 1:L) {
      ix <- which(ids[i] == P)
      if (length(ix) > 0) {
        goldMeans[ix] <- mean(gold[ix])
      }
    }
  }
  sum((map - gold)^2) / sum((gold - goldMeans)^2)
}
```

```{r normalize_ssd, eval = FALSE}
normed <- c(fb = ssdRatio(popk$popfb, popk$pop1k), wp = ssdRatio(popk$wppop, popk$pop1k), ls = ssdRatio(popk$lspop, popk$pop1k), bimep = ssdRatio(popk$pop1k, popk$pop1k), std = ssdRatio(mean(popk$pop1k) + 0 * popk$pop1k, popk$pop1k))

asis <- c(fb = ssdRatio(popk$popfb, popk$pop1k, norm = FALSE), wp = ssdRatio(popk$wppop, popk$pop1k, norm = FALSE), ls = ssdRatio(popk$lspop, popk$pop1k, norm = FALSE), bimep = ssdRatio(popk$pop1k, popk$pop1k, norm = FALSE), std = ssdRatio(mean(popk$pop1k) + 0 * popk$pop1k, popk$pop1k, norm = FALSE))
cbind(normed, asis)
```

```{r group_ssd, eval = FALSE}
ix <- which(popk$lspop > 20000)
c(
  ssdRatio(popk$lspop[-ix], popk$pop1k[-ix]),
  ssdRatio(popk$lspop[-ix], popk$pop1k[-ix], popk$admin2)
)
length(ix)
c(
  ssdRatio(popk$lspop[-ix], popk$pop1k[-ix], norm = FALSE),
  ssdRatio(popk$lspop[-ix], popk$pop1k[-ix], popk$admin2, norm = FALSE)
)
length(ix)
```


```{r df_ssd, eval = FALSE}
A <- data.frame(cbind(
  "HRSL" = c(ssdRatio(popk$popfb, popk$pop1k), ssdRatio(popk$popfb, popk$pop1k, popk$admin2)[1:5, 1]),
  "Landscan" = c(ssdRatio(popk$lspop, popk$pop1k), ssdRatio(popk$lspop, popk$pop1k, popk$admin2)[1:5, 1]),
  "WorldPOP" = c(ssdRatio(popk$wppop, popk$pop1k), ssdRatio(popk$wppop, popk$pop1k, popk$admin2)[1:5, 1])
),
row.names = paste(c("Bioko Island", paste(ssdRatio(popk$wppop, popk$pop1k, popk$admin2)[1:5, 2])))
)
A[6, ] <- -A[6, ]
```

```{r df_ssd_again, eval = FALSE}
B <- data.frame(cbind(
  "HRSL" = c(ssdRatio(popk$popfb, popk$pop1k, norm = FALSE), ssdRatio(popk$popfb, popk$pop1k, popk$admin2, norm = FALSE)[1:5, 1]),
  "Landscan" = c(ssdRatio(popk$lspop, popk$pop1k, norm = FALSE), ssdRatio(popk$lspop, popk$pop1k, popk$admin2, norm = FALSE)[1:5, 1]),
  "WorldPOP" = c(ssdRatio(popk$wppop, popk$pop1k, norm = FALSE), ssdRatio(popk$wppop, popk$pop1k, popk$admin2, norm = FALSE)[1:5, 1])
),
row.names = paste(c("Bioko Island", paste(ssdRatio(popk$wppop, popk$pop1k, popk$admin2)[1:5, 2])))
)
B[6, ] <- -B[6, ]
B
```

```{r look_at_ssd, eval = FALSE}
signif(cbind(B, A), 3)
```



```{r group_ssd_twice, eval = FALSE}
Bioko <- c(
  ssdRatioT(popk$popfb, popk$pop1k),
  ssdRatioT(popk$lspop, popk$pop1k),
  ssdRatioF(popk$wppop, popk$pop1k)
)

Admin2 <- c(
  ssdRatioT(popk$popfb, popk$pop1k, popk$admin2),
  ssdRatioT(popk$lspop, popk$pop1k, popk$admin2),
  ssdRatioT(popk$wppop, popk$pop1k, popk$admin2)
)



fiveID <- c(
  ssdRatioT(popk$popfb, popk$pop1k, popk$fiveId),
  ssdRatioT(popk$lspop, popk$pop1k, popk$fiveId),
  ssdRatioT(popk$wppop, popk$pop1k, popk$fiveId)
)


Admin4 <- c(
  ssdRatioT(popk$popfb, popk$pop1k, popk$admin4),
  ssdRatioT(popk$lspop, popk$pop1k, popk$admin4),
  ssdRatioT(popk$wppop, popk$pop1k, popk$admin4)
)


data.frame(cbind(Admin4, fiveID, Admin2, Bioko), row.names = c("Facebook", "Landscan", "WorldPOP"))
# data.frame(cbind(fiveID, Admin2, Bioko), row.names = c("Facebook", "Landscan", "WorldPOP"))
```

